---
permalink: /
title: "About Me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a third-year Ph.D. candidate in the [Department of Computer Science and Technology](https://www.cs.tsinghua.edu.cn/csen/), [Tsinghua University](https://www.tsinghua.edu.cn/en/), advised by Prof. [Jun Zhu](https://ml.cs.tsinghua.edu.cn/~jun/). Before that, I received my B.S. degree from the Department of Computer Science and Technology, Tsinghua University, and my secondary B.S. degree from the [Department of Psychology](https://www.psych.tsinghua.edu.cn/xlxxen/), Tsinghua University, in June, 2022. I work closely with Prof. [Hang Su](http://suhangss.me/) and Prof. [Yinpeng Dong](http://ml.cs.tsinghua.edu.cn/~yinpeng/).

My research mainly focuses on machine learning, deep learning and their applications in computer vision, etc. Recently, I am interested in the robustness, safety and trustworthiness of deep learning models, especially general-purpose large models.

<font color="red">I am seeking a visiting PhD student position for Fall 2025 and Spring 2026. I am open to self-funded opportunities and look forward to collaborating with leading research groups in trustworthy AI and related fields.</font>

## News

* 2024/09 -- Our paper "[MultiTrust: A Comprehensive Benchmark Towards Trustworthy Multimodal Large Language Models](https://arxiv.org/pdf/2406.07057.pdf)'' has been accepted in NeurIPS2024 Track on Datasets and Benchmarks. This is <font color="red">the first comprehensive benchmark</font> on the trustworthiness of Multimodal LLMs, testing more than 20 modern MLLMs on 32 carefully curated tasks. Find out more at <a href="https://multi-trust.github.io">https://multi-trust.github.io</a>!
* 2024/09 -- Our paper "[PINNacle: A Comprehensive Benchmark of Physics-Informed Neural Networks for Solving PDEs](https://arxiv.org/pdf/2306.08827)'' has been accepted in NeurIPS2024 Track on Datasets and Benchmarks.
* 2024/03 -- Our paper "[Exploring the Transferability of Visual Prompting for Multimodal Large Language Models](https://arxiv.org/pdf/2404.11207.pdf)'' has been accepted in Computer Vision and Pattern Recognition (CVPR) 2024 as <font color="red">Highlight (~top 2.8%)</font>.
* 2024/01 -- Our paper "[Rethinking Model Ensemble in Transfer-based Adversarial Attacks](https://openreview.net/pdf?id=AcJrSoArlh)'' has been accepted in International Conference on Learning Representations (ICLR) 2024.
* 2023/03 -- Our paper "[Understanding the Robustness of 3D Object Detectors with Bird's-Eye-View Representations in Autonomous Driving](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_Understanding_the_Robustness_of_3D_Object_Detection_With_Birds-Eye-View_Representations_CVPR_2023_paper.pdf)'' has been accepted in Computer Vision and Pattern Recognition (CVPR) 2023.
* 2023/03 -- Our paper "[To Make Yourself Invisible with Adversarial Semantic Contours](https://www.sciencedirect.com/science/article/pii/S1077314223000395)''([arxiv](https://arxiv.org/abs/2303.00284)) has been accepted in Computer Vision and Image Understanding (CVIU).
* 2023/12 -- Our team (Yinpeng Dong, Chang Liu, Wenzhao Xiang, **Yichi Zhang**, Haoxing Ye) won <font color="red">the 1st place</font> in the [Evaluating the Adversarial Robustness of Deep Learning Model](https://www.cvmart.net/race/10346/des) track in 2022 International Algorithm Case Competition (Feburary, 2023).

<!-- * I received Beijing Outstanding Graduates in June, 2022.
* I received Tsinghua Outstanding Graduates in June, 2022.
* I received Beijing Merit Student in September, 2021.
* Our team (Xiao Yang, **Yichi Zhang**, Shilong Liu) won <font color="red">the 2nd place (2/1599)</font> in the CVPR 2021 Security AI Challenger [Unrestricted Adversarial Attacks on ImageNet](https://tianchi.aliyun.com/competition/entrance/531853/introduction) (June, 2021).
* Our team (**Yichi Zhang**, Zijiang Zhu, Wenzhao Xiang) won <font color="red">the 8th place (8/1814)</font> in the CIKM 2020 Challenge [Adversarial Challenge on Object Detection](https://tianchi.aliyun.com/competition/entrance/531806/introduction?spm=5176.12281925.0.0.43357137G4aiMK) (September, 2020). -->


